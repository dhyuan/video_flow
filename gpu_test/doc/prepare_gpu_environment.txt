



https://liguoqinjim.com/post/tensorflow/tensorflow%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AEgpu/

1) pip install tensorflow

2) pip install tensorflow-gpu


3)
通过 /usr/local/cuda-10.1/extras/demo_suite/deviceQuery  查询CUDA版本。
在页面 https://developer.nvidia.com/rdp/cudnn-archive  下载CUDA版本对应的 cuDNN GPU加速库。

4）确认 tensorflow 是否可以使用GPU。
tf.test.is_gpu_available()


https://developer.nvidia.com/rdp/cudnn-archive







===============
https://www.tensorflow.org/install
===============

pip install --upgrade pip
pip install tensorflow

wget http://developer.download.nvidia.com/compute/cuda/10.1/Prod/local_installers/cuda_10.1.243_418.87.00_linux.run
sudo sh cuda_10.1.243_418.87.00_linux.run

# 下载合适版本的cuDNN  https://developer.nvidia.com/rdp/cudnn-download
# 安装 cuDNN  https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html
tar -xzvf cudnn-x.x-linux-x64-v8.x.x.x.tgz
cp cuda/include/cudnn*.h /usr/local/cuda/include
cp cuda/lib64/libcudnn* /usr/local/cuda/lib64
chmod a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn*

# 验证cuDNN 安装成功。 Copy the cuDNN sample to a writable path.
$cp -r /usr/src/cudnn_samples_v8/ $HOME
Go to the writable path.
$ cd  $HOME/cudnn_samples_v8/mnistCUDNN
Compile the mnistCUDNN sample.
$make clean && make
Run the mnistCUDNN sample.
$ ./mnistCUDNN
If cuDNN is properly installed and running on your Linux system, you will see a message similar to the following:
Test passed!

========== 基于Docker的tensorflow =======
# 安装 docker   https://docs.docker.com/engine/install/centos/
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
yum install docker-ce docker-ce-cli containerd.io

# 安装 nvidia-container-toolkit  https://github.com/NVIDIA/nvidia-docker
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | sudo tee /etc/yum.repos.d/nvidia-docker.repo
sudo yum install -y nvidia-container-toolkit
sudo systemctl restart docker

# Test nvidia-smi with the latest official CUDA image
docker run --gpus all nvidia/cuda:10.0-base nvidia-smi

